{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-06 Deeplab v3+\n",
    "\n",
    "Please run the code with \"VScode-devcontainer\".\n",
    "\n",
    "> You can find the tutorial provided by Visual Studio Code here :   \n",
    "> [https://code.visualstudio.com/docs/devcontainers/containers](https://code.visualstudio.com/docs/devcontainers/containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import network\n",
    "from datasets import Cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_synchronized():\n",
    "    # pytorch-accurate time\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    return time.time()\n",
    "\n",
    "\n",
    "def set_bn_momentum(model, momentum=0.1):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.momentum = momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(inputs, result, model_name, ckpt):\n",
    "    os.makedirs(result, exist_ok=True)\n",
    "    decode_fn = Cityscapes.decode_target\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device: %s\" % device)\n",
    "\n",
    "    # Setup dataloader\n",
    "    image_files = []\n",
    "    if os.path.isdir(inputs):\n",
    "        for ext in [\"png\", \"jpeg\", \"jpg\", \"JPEG\"]:\n",
    "            files = glob(os.path.join(inputs, \"**/*.%s\" % (ext)), recursive=True)\n",
    "            if len(files) > 0:\n",
    "                image_files.extend(files)\n",
    "    elif os.path.isfile(inputs):\n",
    "        image_files.append(inputs)\n",
    "\n",
    "    # Set up model (all models are 'constructed at network.modeling) / output_stride : 8 or 16\n",
    "    model = network.modeling.__dict__[model_name](num_classes=19, output_stride=16)\n",
    "\n",
    "    set_bn_momentum(model.backbone, momentum=0.01)\n",
    "\n",
    "    checkpoint = torch.load(ckpt, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    print(\"Resume model from %s\" % ckpt)\n",
    "    del checkpoint\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        for img_path in tqdm(image_files):\n",
    "            ext = os.path.basename(img_path).split(\".\")[-1]\n",
    "            img_name = os.path.basename(img_path)[: -len(ext) - 1]\n",
    "            origin_img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = transform(origin_img).unsqueeze(0)  # To tensor of NCHW\n",
    "            img = img.to(device)\n",
    "\n",
    "            t1 = time_synchronized()\n",
    "            pred = model(img).max(1)[1].cpu().numpy()[0]  # HW\n",
    "            t2 = time_synchronized()\n",
    "\n",
    "            print(f\"Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference.\")\n",
    "\n",
    "            colorized_preds = decode_fn(pred).astype(\"uint8\")\n",
    "            colorized_preds = Image.fromarray(colorized_preds)\n",
    "            colorized_preds = Image.blend(colorized_preds, origin_img, alpha=0.4)\n",
    "\n",
    "            if result:\n",
    "                colorized_preds.save(os.path.join(result, img_name + \".png\"))\n",
    "\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(colorized_preds)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_video(path, result, model_name, ckpt):\n",
    "    decode_fn = Cityscapes.decode_target\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device: %s\" % device)\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    video_writer = cv2.VideoWriter(result, cv2.VideoWriter_fourcc(*\"mp4v\"), 30, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "\n",
    "    # Set up model (all models are 'constructed at network.modeling) / output_stride : 8 or 16\n",
    "    model = network.modeling.__dict__[model_name](num_classes=19, output_stride=16)\n",
    "\n",
    "    set_bn_momentum(model.backbone, momentum=0.01)\n",
    "\n",
    "    checkpoint = torch.load(ckpt, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    print(\"Resume model from %s\" % ckpt)\n",
    "    del checkpoint\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Start to predict ...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        total_img = 0\n",
    "\n",
    "        t1 = time_synchronized()\n",
    "        while True:\n",
    "            success, origin_img = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "            else:\n",
    "                total_img += 1\n",
    "\n",
    "            img = transform(origin_img).unsqueeze(0)  # To tensor of NCHW\n",
    "            img = img.to(device)\n",
    "\n",
    "            pred = model(img).max(1)[1].cpu().numpy()[0]  # HW\n",
    "\n",
    "            colorized_preds = decode_fn(pred).astype(\"uint8\")\n",
    "\n",
    "            colorized_preds = cv2.addWeighted(colorized_preds, 0.5, origin_img, 0.5, 0)\n",
    "            video_writer.write(colorized_preds)\n",
    "\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        print(f\"Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, Total frame : {total_img}.\")\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictImage():\n",
    "    inputs = \"test_inputs/test1.png\"\n",
    "    result = \"test_results\"\n",
    "\n",
    "    model_name = \"deeplabv3plus_mobilenet\"\n",
    "    ckpt = \"weights/best_deeplabv3plus_mobilenet_cityscapes_os16.pth\"\n",
    "\n",
    "    # model_name = \"deeplabv3plus_resnet101\"\n",
    "    # ckpt = \"weights/best_deeplabv3plus_resnet101_cityscapes_os16.pth\"\n",
    "\n",
    "    predict_images(inputs, result, model_name, ckpt)\n",
    "\n",
    "\n",
    "# PredictImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Resume model from weights/best_deeplabv3plus_resnet101_cityscapes_os16.pth\n",
      "Start to predict ...\n",
      "Done. (54687.9ms) Inference, Total frame : 300.\n"
     ]
    }
   ],
   "source": [
    "def PredictVideo():\n",
    "    inputs = \"./test_inputs/test.mp4\"\n",
    "    result = \"./test_results/test.mp4\"\n",
    "\n",
    "    # model_name = \"deeplabv3plus_mobilenet\"\n",
    "    # ckpt = \"weights/best_deeplabv3plus_mobilenet_cityscapes_os16.pth\"\n",
    "\n",
    "    model_name = \"deeplabv3plus_resnet101\"\n",
    "    ckpt = \"weights/best_deeplabv3plus_resnet101_cityscapes_os16.pth\"\n",
    "\n",
    "    predict_video(inputs, result, model_name, ckpt)\n",
    "\n",
    "\n",
    "PredictVideo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
